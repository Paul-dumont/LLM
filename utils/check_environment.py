#!/usr/bin/env python3
"""
Script de v√©rification compl√®te de l'environnement pour entra√Ænement LLM
√Ä lancer sur le n≈ìud de connexion Longleaf (CPU) avant de soumettre des jobs GPU.

‚ö†Ô∏è  SCRIPT EN LECTURE SEULE - Ne modifie pas votre environnement existant
‚úÖ V√©rifie seulement si tout est pr√™t pour l'entra√Ænement

Usage: python check_environment.py
"""

import sys, os
from pathlib import Path
import re, random
import traceback
from datetime import datetime

def print_status(msg, status="INFO"):
    timestamp = datetime.now().strftime("%H:%M:%S")
    symbols = {"OK": "‚úÖ", "ERROR": "‚ùå", "WARN": "‚ö†Ô∏è", "INFO": "‚ÑπÔ∏è"}
    symbol = symbols.get(status, "‚ÑπÔ∏è")
    print(f"[{timestamp}] {symbol} {msg}")

def check_python_version():
    """V√©rifier la version Python"""
    print_status("V√©rification de Python", "INFO")
    version = sys.version_info
    print_status(f"Version Python: {version.major}.{version.minor}.{version.micro}")
    
    if version.major != 3 or version.minor < 8:
        print_status(f"ATTENTION: Python {version.major}.{version.minor} d√©tect√©. Recommand√©: Python 3.8+", "WARN")
    else:
        print_status("Version Python OK", "OK")

def check_imports():
    """V√©rifier les imports critiques"""
    print_status("V√©rification des librairies Python", "INFO")
    
    required_packages = {
        'torch': 'PyTorch',
        'transformers': 'Transformers',
        'datasets': 'Datasets',
        'trl': 'TRL',
        'peft': 'PEFT',
        'accelerate': 'Accelerate'
    }
    
    failed_imports = []
    
    for package, name in required_packages.items():
        try:
            mod = __import__(package)
            version = getattr(mod, '__version__', 'version inconnue')
            print_status(f"{name}: {version}", "OK")
        except ImportError as e:
            print_status(f"√âCHEC import {name}: {e}", "ERROR")
            failed_imports.append(package)
    
    return failed_imports

def check_torch_capabilities():
    """V√©rifier les capacit√©s PyTorch"""
    print_status("V√©rification des capacit√©s PyTorch", "INFO")
    
    try:
        import torch
        
        # Version PyTorch
        print_status(f"PyTorch version: {torch.__version__}")
        
        # CUDA disponibilit√© (m√™me sur CPU, on v√©rifie la compilation)
        cuda_available = torch.cuda.is_available()
        print_status(f"CUDA compil√©: {cuda_available}")
        
        if cuda_available:
            print_status("CUDA trouv√© - parfait pour GPU jobs!", "OK")
        else:
            print_status("CUDA non trouv√© - v√©rifiez l'installation pour jobs GPU", "WARN")
        
        # Test de cr√©ation de tenseur
        x = torch.tensor([1.0, 2.0, 3.0])
        print_status(f"Test tensor: {x.dtype} - {x.device}", "OK")
        
        # V√©rifier bfloat16 support
        if hasattr(torch, 'bfloat16'):
            print_status("Support bfloat16: disponible", "OK")
        else:
            print_status("Support bfloat16: non disponible", "WARN")
            
        return True
        
    except Exception as e:
        print_status(f"Erreur PyTorch: {e}", "ERROR")
        return False

def check_transformers_models():
    """V√©rifier l'acc√®s aux mod√®les Transformers"""
    print_status("V√©rification de l'acc√®s aux mod√®les", "INFO")
    
    try:
        from transformers import AutoTokenizer
        
        # Test avec un petit mod√®le pour v√©rifier la connectivit√© HF
        print_status("Test de t√©l√©chargement tokenizer (petit mod√®le)...")
        tok = AutoTokenizer.from_pretrained("microsoft/DialoGPT-small")
        print_status("Acc√®s HuggingFace Hub: OK", "OK")
        
        # Test des mod√®les de votre projet
        test_models = [
            "Qwen/Qwen2.5-0.5B-Instruct",
            "meta-llama/Llama-3.2-8B-Instruct"  # Celui-ci n√©cessite peut-√™tre un token
        ]
        
        for model_id in test_models:
            try:
                print_status(f"Test acc√®s: {model_id}...")
                tok = AutoTokenizer.from_pretrained(model_id)
                print_status(f"‚úì {model_id}: accessible", "OK")
            except Exception as e:
                if "token" in str(e).lower() or "authentication" in str(e).lower():
                    print_status(f"‚ö† {model_id}: n√©cessite un token HF", "WARN")
                else:
                    print_status(f"‚úó {model_id}: {str(e)[:100]}", "ERROR")
        
        return True
        
    except Exception as e:
        print_status(f"Erreur acc√®s mod√®les: {e}", "ERROR")
        return False

def check_data_structure():
    """V√©rifier la structure des donn√©es"""
    print_status("V√©rification de la structure des donn√©es", "INFO")
    
    # V√©rifier les dossiers requis (√† la racine du projet)
    required_dirs = ["../Data_input", "../Data_output"]
    missing_dirs = []
    
    for dir_path_str in required_dirs:
        dir_path = Path(dir_path_str)
        dir_name = dir_path.name  # Nom pour l'affichage
        if dir_path.exists():
            files = list(dir_path.glob("*.txt"))
            print_status(f"{dir_name}: {len(files)} fichiers .txt", "OK")
        else:
            print_status(f"{dir_name}: dossier manquant", "ERROR")
            missing_dirs.append(dir_name)
    
    # V√©rifier la correspondance des fichiers
    if not missing_dirs:
        try:
            def get_id(name):
                m = re.match(r"(B\d+)", name)
                return m.group(1) if m else None
            
            input_files = {get_id(p.name): p for p in Path("../Data_input").glob("*.txt")}
            output_files = {get_id(p.name): p for p in Path("../Data_output").glob("*.txt")}
            
            common_ids = set(input_files.keys()) & set(output_files.keys())
            print_status(f"Fichiers appair√©s: {len(common_ids)} paires trouv√©es", "OK")
            
            if len(common_ids) == 0:
                print_status("AUCUNE paire input/output trouv√©e!", "ERROR")
            elif len(common_ids) < 5:
                print_status(f"Seulement {len(common_ids)} paires - entra√Ænement limit√©", "WARN")
                
        except Exception as e:
            print_status(f"Erreur v√©rification donn√©es: {e}", "ERROR")
    
    return len(missing_dirs) == 0

def check_file_permissions():
    """V√©rifier les permissions de fichiers (LECTURE SEULE)"""
    print_status("V√©rification des permissions (lecture seule)", "INFO")
    
    # V√©rifier les permissions existantes sans rien cr√©er (√† la racine du projet)
    test_dirs = [("../runs", "runs"), ("../Data_predict", "Data_predict"), ("../logs", "logs")]
    
    for dir_path_str, dir_name in test_dirs:
        dir_path = Path(dir_path_str)
        if dir_path.exists():
            if dir_path.is_dir() and os.access(dir_path, os.W_OK):
                print_status(f"Permissions {dir_name}: OK (existe et accessible)", "OK")
            else:
                print_status(f"Permissions {dir_name}: Limit√© (existe mais acc√®s restreint)", "WARN")
        else:
            # V√©rifier si on peut cr√©er dans le r√©pertoire parent
            parent_dir = dir_path.parent
            if os.access(parent_dir, os.W_OK):
                print_status(f"Permissions {dir_name}: OK (peut √™tre cr√©√©)", "OK")
            else:
                print_status(f"Permissions {dir_name}: √âCHEC (ne peut pas √™tre cr√©√©)", "ERROR")
                return False
    
    # V√©rifier permissions √©criture dans le r√©pertoire courant
    try:
        current_dir = Path(".")
        if os.access(current_dir, os.W_OK):
            print_status("Permissions √©criture: OK (r√©pertoire accessible)", "OK")
        else:
            print_status("Permissions √©criture: √âCHEC (r√©pertoire non accessible)", "ERROR")
            return False
    except Exception as e:
        print_status(f"Permissions √©criture: √âCHEC - {e}", "ERROR")
        return False
    
    return True

def check_memory():
    """V√©rifier la m√©moire disponible"""
    print_status("V√©rification m√©moire syst√®me", "INFO")
    
    try:
        import psutil
        
        # M√©moire totale
        mem = psutil.virtual_memory()
        total_gb = mem.total / (1024**3)
        available_gb = mem.available / (1024**3)
        
        print_status(f"M√©moire totale: {total_gb:.1f} GB")
        print_status(f"M√©moire disponible: {available_gb:.1f} GB")
        
        if available_gb < 2:
            print_status("M√©moire faible - risque de probl√®me", "WARN")
        else:
            print_status("M√©moire suffisante", "OK")
            
    except ImportError:
        print_status("psutil non disponible - impossible de v√©rifier la m√©moire", "WARN")

def check_environment_variables():
    """V√©rifier les variables d'environnement importantes"""
    print_status("V√©rification variables d'environnement", "INFO")
    
    important_vars = {
        'HF_HOME': 'Cache HuggingFace',
        'CUDA_VISIBLE_DEVICES': 'Devices CUDA visibles',
        'PYTHONPATH': 'Chemin Python'
    }
    
    for var, desc in important_vars.items():
        value = os.environ.get(var)
        if value:
            print_status(f"{desc}: {value[:100]}")
        else:
            print_status(f"{desc}: non d√©fini")

def run_mini_training_test():
    """Test d'entra√Ænement minimal pour v√©rifier la pipeline compl√®te"""
    print_status("Test de pipeline d'entra√Ænement minimal", "INFO")
    
    try:
        from datasets import Dataset
        from transformers import AutoTokenizer
        
        # Cr√©er un mini dataset de test
        test_data = [
            {"text": "[INST]Test input 1[/INST]Test output 1"},
            {"text": "[INST]Test input 2[/INST]Test output 2"}
        ]
        
        dataset = Dataset.from_list(test_data)
        print_status("Cr√©ation dataset test: OK", "OK")
        
        # Test tokenizer
        tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-small")
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        # Test tokenisation
        encoded = tokenizer(test_data[0]["text"], return_tensors="pt")
        print_status(f"Tokenisation test: {encoded['input_ids'].shape}", "OK")
        
        print_status("Pipeline compl√®te: OK", "OK")
        return True
        
    except Exception as e:
        print_status(f"√âchec pipeline test: {e}", "ERROR")
        return False

def main():
    print("="*60)
    print("üîç V√âRIFICATION ENVIRONNEMENT LLM LONGLEAF")
    print("‚ö†Ô∏è  MODE LECTURE SEULE - Aucune modification")
    print("="*60)
    
    all_checks = []
    
    # Ex√©cuter toutes les v√©rifications
    all_checks.append(("Python Version", True))  # Toujours OK
    check_python_version()
    
    print("\n" + "-"*40)
    failed_imports = check_imports()
    all_checks.append(("Imports Python", len(failed_imports) == 0))
    
    print("\n" + "-"*40)
    torch_ok = check_torch_capabilities()
    all_checks.append(("PyTorch", torch_ok))
    
    print("\n" + "-"*40)
    models_ok = check_transformers_models()
    all_checks.append(("Acc√®s Mod√®les", models_ok))
    
    print("\n" + "-"*40)
    data_ok = check_data_structure()
    all_checks.append(("Structure Donn√©es", data_ok))
    
    print("\n" + "-"*40)
    perms_ok = check_file_permissions()
    all_checks.append(("Permissions", perms_ok))
    
    print("\n" + "-"*40)
    check_memory()
    
    print("\n" + "-"*40)
    check_environment_variables()
    
    print("\n" + "-"*40)
    pipeline_ok = run_mini_training_test()
    all_checks.append(("Pipeline Test", pipeline_ok))
    
    # R√©sum√© final
    print("\n" + "="*60)
    print("üìä R√âSUM√â DES V√âRIFICATIONS")
    print("="*60)
    
    passed = 0
    total = len(all_checks)
    
    for check_name, check_result in all_checks:
        status_symbol = "‚úÖ" if check_result else "‚ùå"
        print(f"{status_symbol} {check_name}")
        if check_result:
            passed += 1
    
    print(f"\nR√©sultat: {passed}/{total} v√©rifications r√©ussies")
    
    if passed == total:
        print_status("üöÄ ENVIRONNEMENT PR√äT POUR L'ENTRA√éNEMENT!", "OK")
        print("Vous pouvez soumettre vos jobs GPU en toute confiance.")
        return 0
    else:
        print_status("‚ö†Ô∏è  PROBL√àMES D√âTECT√âS", "WARN")
        print("Corrigez les erreurs avant de soumettre des jobs GPU.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
